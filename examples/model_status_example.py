#!/usr/bin/env python3
"""
examples/model_status_example.py
vLLM ëª¨ë¸ ìƒíƒœ ì²´í¬ ì˜ˆì œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” vLLM API ì„œë²„ì˜ ëª¨ë¸ ìƒíƒœë¥¼ ì²´í¬í•˜ê³ 
ë‹¤ì–‘í•œ ì •ë³´ë¥¼ í™•ì¸í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    python examples/model_status_example.py
    python examples/model_status_example.py --api-base http://localhost:8000
    python examples/model_status_example.py --detailed --export-json
"""

import argparse
import asyncio
import json
import sys
import time
from datetime import datetime
from typing import Dict, List, Optional, Any
import aiohttp
import requests
from dataclasses import dataclass, asdict
from pathlib import Path

@dataclass
class ModelInfo:
    """ëª¨ë¸ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    id: str
    object: str
    created: Optional[int] = None
    owned_by: Optional[str] = None
    permission: Optional[List[Dict]] = None
    root: Optional[str] = None
    parent: Optional[str] = None

@dataclass
class ServerStatus:
    """ì„œë²„ ìƒíƒœ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    is_healthy: bool
    response_time_ms: float
    timestamp: str
    error_message: Optional[str] = None

@dataclass
class ModelStatus:
    """ëª¨ë¸ ìƒíƒœ ì¢…í•© ì •ë³´"""
    server_status: ServerStatus
    models: List[ModelInfo]
    model_count: int
    primary_model: Optional[str] = None

class ModelStatusChecker:
    """ëª¨ë¸ ìƒíƒœ ì²´í¬ í´ë˜ìŠ¤"""
    
    def __init__(self, api_base: str = "http://localhost:8000"):
        self.api_base = api_base.rstrip('/')
        self.session = requests.Session()
        self.session.timeout = 30
        
    def check_server_health(self) -> ServerStatus:
        """ì„œë²„ í—¬ìŠ¤ ìƒíƒœ ì²´í¬"""
        start_time = time.time()
        timestamp = datetime.now().isoformat()
        
        try:
            response = self.session.get(f"{self.api_base}/health")
            response_time_ms = (time.time() - start_time) * 1000
            
            if response.status_code == 200:
                return ServerStatus(
                    is_healthy=True,
                    response_time_ms=response_time_ms,
                    timestamp=timestamp
                )
            else:
                return ServerStatus(
                    is_healthy=False,
                    response_time_ms=response_time_ms,
                    timestamp=timestamp,
                    error_message=f"HTTP {response.status_code}: {response.text}"
                )
                
        except requests.exceptions.ConnectionError:
            return ServerStatus(
                is_healthy=False,
                response_time_ms=0,
                timestamp=timestamp,
                error_message="Connection refused - ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•Šê±°ë‚˜ ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        except requests.exceptions.Timeout:
            return ServerStatus(
                is_healthy=False,
                response_time_ms=0,
                timestamp=timestamp,
                error_message="Request timeout - ì„œë²„ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
        except Exception as e:
            return ServerStatus(
                is_healthy=False,
                response_time_ms=0,
                timestamp=timestamp,
                error_message=f"Unexpected error: {str(e)}"
            )
    
    def get_models(self) -> List[ModelInfo]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            response = self.session.get(f"{self.api_base}/v1/models")
            
            if response.status_code == 200:
                data = response.json()
                models = []
                
                for model_data in data.get("data", []):
                    model = ModelInfo(
                        id=model_data.get("id", "unknown"),
                        object=model_data.get("object", "model"),
                        created=model_data.get("created"),
                        owned_by=model_data.get("owned_by"),
                        permission=model_data.get("permission"),
                        root=model_data.get("root"),
                        parent=model_data.get("parent")
                    )
                    models.append(model)
                
                return models
            else:
                print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: HTTP {response.status_code}")
                return []
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def get_model_details(self, model_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • ëª¨ë¸ì˜ ì„¸ë¶€ ì •ë³´ ì¡°íšŒ"""
        try:
            response = self.session.get(f"{self.api_base}/v1/models/{model_id}")
            
            if response.status_code == 200:
                return response.json()
            else:
                print(f"âŒ ëª¨ë¸ '{model_id}' ì„¸ë¶€ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ '{model_id}' ì„¸ë¶€ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    async def test_model_inference(self, model_id: str, prompt: str = "Hello, how are you?") -> Dict[str, Any]:
        """ëª¨ë¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": model_id,
                    "prompt": prompt,
                    "max_tokens": 50,
                    "temperature": 0.7,
                    "top_p": 0.9
                }
                
                start_time = time.time()
                async with session.post(
                    f"{self.api_base}/v1/completions",
                    json=payload,
                    timeout=30
                ) as response:
                    end_time = time.time()
                    
                    if response.status == 200:
                        result = await response.json()
                        return {
                            "success": True,
                            "response_time": end_time - start_time,
                            "tokens_generated": len(result.get("choices", [{}])[0].get("text", "").split()),
                            "result": result
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "success": False,
                            "response_time": end_time - start_time,
                            "error": f"HTTP {response.status}: {error_text}"
                        }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def check_all_status(self) -> ModelStatus:
        """ëª¨ë“  ìƒíƒœ ì •ë³´ ì¢…í•© ì²´í¬"""
        print("ğŸ” vLLM API ì„œë²„ ìƒíƒœ ì²´í¬ ì‹œì‘...")
        
        # ì„œë²„ í—¬ìŠ¤ ì²´í¬
        print("\n1ï¸âƒ£ ì„œë²„ í—¬ìŠ¤ ì²´í¬ ì¤‘...")
        server_status = self.check_server_health()
        
        if not server_status.is_healthy:
            print(f"âŒ ì„œë²„ ìƒíƒœ: ë¹„ì •ìƒ")
            print(f"   ì˜¤ë¥˜: {server_status.error_message}")
            return ModelStatus(
                server_status=server_status,
                models=[],
                model_count=0
            )
        
        print(f"âœ… ì„œë²„ ìƒíƒœ: ì •ìƒ (ì‘ë‹µì‹œê°„: {server_status.response_time_ms:.1f}ms)")
        
        # ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
        print("\n2ï¸âƒ£ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘...")
        models = self.get_models()
        
        if not models:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return ModelStatus(
                server_status=server_status,
                models=[],
                model_count=0
            )
        
        print(f"âœ… {len(models)}ê°œì˜ ëª¨ë¸ ë°œê²¬")
        
        # ì£¼ìš” ëª¨ë¸ ì‹ë³„
        primary_model = models[0].id if models else None
        
        return ModelStatus(
            server_status=server_status,
            models=models,
            model_count=len(models),
            primary_model=primary_model
        )

def print_detailed_status(status: ModelStatus, checker: ModelStatusChecker):
    """ìƒì„¸ ìƒíƒœ ì •ë³´ ì¶œë ¥"""
    print(f"\n{'='*60}")
    print("ğŸ“Š ìƒì„¸ ìƒíƒœ ë¦¬í¬íŠ¸")
    print(f"{'='*60}")
    
    # ì„œë²„ ì •ë³´
    print(f"\nğŸ–¥ï¸  ì„œë²„ ì •ë³´:")
    print(f"   â€¢ API ì£¼ì†Œ: {checker.api_base}")
    print(f"   â€¢ ìƒíƒœ: {'âœ… ì •ìƒ' if status.server_status.is_healthy else 'âŒ ë¹„ì •ìƒ'}")
    print(f"   â€¢ ì‘ë‹µì‹œê°„: {status.server_status.response_time_ms:.1f}ms")
    print(f"   â€¢ ì²´í¬ ì‹œê°„: {status.server_status.timestamp}")
    
    if status.server_status.error_message:
        print(f"   â€¢ ì˜¤ë¥˜: {status.server_status.error_message}")
    
    # ëª¨ë¸ ì •ë³´
    print(f"\nğŸ¤– ëª¨ë¸ ì •ë³´:")
    print(f"   â€¢ ì´ ëª¨ë¸ ìˆ˜: {status.model_count}")
    
    if status.primary_model:
        print(f"   â€¢ ì£¼ìš” ëª¨ë¸: {status.primary_model}")
    
    if status.models:
        print(f"\n   ğŸ“‹ ëª¨ë¸ ëª©ë¡:")
        for i, model in enumerate(status.models, 1):
            print(f"      {i}. {model.id}")
            if model.owned_by:
                print(f"         â€¢ ì†Œìœ ì: {model.owned_by}")
            if model.created:
                created_date = datetime.fromtimestamp(model.created).strftime("%Y-%m-%d %H:%M:%S")
                print(f"         â€¢ ìƒì„± ì‹œê°„: {created_date}")

def print_summary_status(status: ModelStatus):
    """ìš”ì•½ ìƒíƒœ ì •ë³´ ì¶œë ¥"""
    print(f"\n{'='*40}")
    print("ğŸ“‹ ìƒíƒœ ìš”ì•½")
    print(f"{'='*40}")
    
    # ì„œë²„ ìƒíƒœ
    server_emoji = "âœ…" if status.server_status.is_healthy else "âŒ"
    print(f"{server_emoji} ì„œë²„: {'ì •ìƒ' if status.server_status.is_healthy else 'ë¹„ì •ìƒ'}")
    
    if status.server_status.is_healthy:
        print(f"âš¡ ì‘ë‹µì‹œê°„: {status.server_status.response_time_ms:.1f}ms")
    
    # ëª¨ë¸ ìƒíƒœ
    if status.model_count > 0:
        print(f"ğŸ¤– ëª¨ë¸: {status.model_count}ê°œ ì‚¬ìš© ê°€ëŠ¥")
        if status.primary_model:
            print(f"ğŸ¯ ì£¼ìš” ëª¨ë¸: {status.primary_model}")
    else:
        print("âŒ ëª¨ë¸: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ")

async def test_model_performance(checker: ModelStatusChecker, model_id: str):
    """ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ§ª ëª¨ë¸ '{model_id}' ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤‘...")
    
    test_prompts = [
        "Hello, how are you?",
        "What is the capital of France?",
        "Explain machine learning in simple terms."
    ]
    
    total_time = 0
    total_tokens = 0
    successful_tests = 0
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"   í…ŒìŠ¤íŠ¸ {i}/{len(test_prompts)}: {prompt[:30]}...")
        
        result = await checker.test_model_inference(model_id, prompt)
        
        if result["success"]:
            successful_tests += 1
            total_time += result["response_time"]
            total_tokens += result["tokens_generated"]
            print(f"      âœ… ì„±ê³µ ({result['response_time']:.2f}ì´ˆ, {result['tokens_generated']}í† í°)")
        else:
            print(f"      âŒ ì‹¤íŒ¨: {result['error']}")
    
    if successful_tests > 0:
        avg_time = total_time / successful_tests
        avg_tokens = total_tokens / successful_tests
        tokens_per_second = avg_tokens / avg_time if avg_time > 0 else 0
        
        print(f"\nğŸ“Š ì„±ëŠ¥ ìš”ì•½:")
        print(f"   â€¢ ì„±ê³µë¥ : {successful_tests}/{len(test_prompts)} ({successful_tests/len(test_prompts)*100:.1f}%)")
        print(f"   â€¢ í‰ê·  ì‘ë‹µì‹œê°„: {avg_time:.2f}ì´ˆ")
        print(f"   â€¢ í‰ê·  í† í° ìˆ˜: {avg_tokens:.1f}ê°œ")
        print(f"   â€¢ í† í°/ì´ˆ: {tokens_per_second:.1f}")
    else:
        print(f"\nâŒ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

def export_to_json(status: ModelStatus, filename: str):
    """ìƒíƒœ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    try:
        # ë°ì´í„° ì§ë ¬í™”ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ ë³€í™˜
        status_dict = {
            "server_status": asdict(status.server_status),
            "models": [asdict(model) for model in status.models],
            "model_count": status.model_count,
            "primary_model": status.primary_model,
            "export_timestamp": datetime.now().isoformat()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(status_dict, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ìƒíƒœ ì •ë³´ê°€ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ JSON ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="vLLM ëª¨ë¸ ìƒíƒœ ì²´í¬ ë„êµ¬")
    
    parser.add_argument(
        "--api-base",
        default="http://localhost:8000",
        help="vLLM API ì„œë²„ ì£¼ì†Œ (ê¸°ë³¸ê°’: http://localhost:8000)"
    )
    
    parser.add_argument(
        "--detailed",
        action="store_true",
        help="ìƒì„¸í•œ ìƒíƒœ ì •ë³´ í‘œì‹œ"
    )
    
    parser.add_argument(
        "--test-performance",
        action="store_true",
        help="ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
    )
    
    parser.add_argument(
        "--export-json",
        metavar="FILENAME",
        help="ìƒíƒœ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"
    )
    
    parser.add_argument(
        "--model-id",
        help="í…ŒìŠ¤íŠ¸í•  íŠ¹ì • ëª¨ë¸ ID (ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œ ì‚¬ìš©)"
    )
    
    args = parser.parse_args()
    
    print("ğŸš€ vLLM ëª¨ë¸ ìƒíƒœ ì²´í¬ ë„êµ¬")
    print(f"ğŸ“¡ ì—°ê²° ëŒ€ìƒ: {args.api_base}")
    
    # ìƒíƒœ ì²´í¬ ì‹¤í–‰
    checker = ModelStatusChecker(args.api_base)
    status = checker.check_all_status()
    
    # ê²°ê³¼ ì¶œë ¥
    if args.detailed:
        print_detailed_status(status, checker)
    else:
        print_summary_status(status)
    
    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    if args.test_performance and status.server_status.is_healthy:
        model_to_test = args.model_id or status.primary_model
        
        if model_to_test:
            await test_model_performance(checker, model_to_test)
        else:
            print("âŒ í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # JSON ë‚´ë³´ë‚´ê¸°
    if args.export_json:
        filename = args.export_json if args.export_json.endswith('.json') else f"{args.export_json}.json"
        export_to_json(status, filename)
    
    # ìµœì¢… ìƒíƒœ ì½”ë“œ ë°˜í™˜
    if not status.server_status.is_healthy:
        print(f"\nâŒ ì„œë²„ ìƒíƒœê°€ ë¹„ì •ìƒì…ë‹ˆë‹¤.")
        sys.exit(1)
    elif status.model_count == 0:
        print(f"\nâš ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        sys.exit(1)
    else:
        print(f"\nâœ… ëª¨ë“  ìƒíƒœê°€ ì •ìƒì…ë‹ˆë‹¤.")
        sys.exit(0)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)
