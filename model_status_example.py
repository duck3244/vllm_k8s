#!/usr/bin/env python3
"""
ëª¨ë¸ ìƒíƒœ ì²´í¬ ì‚¬ìš© ì˜ˆì œ
"""

import requests
import time
import json
from datetime import datetime

# API ê¸°ë³¸ URL
BASE_URL = "http://localhost:8000/api/v1"

def check_model_status():
    """ëª¨ë¸ í˜„ì¬ ìƒíƒœ í™•ì¸"""
    try:
        response = requests.get(f"{BASE_URL}/model/status")
        response.raise_for_status()
        
        data = response.json()
        print("ğŸ¤– ëª¨ë¸ ìƒíƒœ ì •ë³´")
        print("=" * 50)
        print(f"ìƒíƒœ: {data['status']}")
        print(f"ë§ˆì§€ë§‰ ì²´í¬: {data['last_check']}")
        print(f"ìˆ˜í–‰ëœ ì²´í¬ ìˆ˜: {data['checks_performed']}")
        print(f"í‰ê·  ì‘ë‹µì‹œê°„: {data['response_time_avg']:.2f}ì´ˆ")
        print(f"95% ì‘ë‹µì‹œê°„: {data['response_time_p95']:.2f}ì´ˆ")
        print(f"ì—ëŸ¬ìœ¨: {data['error_rate']:.1%}")
        print(f"ì²˜ë¦¬ëŸ‰: {data['throughput']:.1f} tokens/sec")
        
        if data['gpu_memory_usage']:
            print(f"GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {data['gpu_memory_usage']:.1f}%")
        if data['gpu_temperature']:
            print(f"GPU ì˜¨ë„: {data['gpu_temperature']:.1f}Â°C")
        
        print(f"í™œì„± ìš”ì²­ ìˆ˜: {data['active_requests']}")
        
        # ì•Œë¦¼ ì •ë³´
        if data['alerts']:
            print("\nâš ï¸  í™œì„± ì•Œë¦¼:")
            for alert in data['alerts']:
                print(f"  - {alert['severity'].upper()}: {alert['message']}")
        else:
            print("\nâœ… í™œì„± ì•Œë¦¼ ì—†ìŒ")
        
        return data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ëª¨ë¸ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

def run_health_check(include_inference=False, test_prompt=None):
    """ìˆ˜ë™ í—¬ìŠ¤ì²´í¬ ì‹¤í–‰"""
    try:
        payload = {
            "include_inference_test": include_inference
        }
        if test_prompt:
            payload["test_prompt"] = test_prompt
        
        response = requests.post(
            f"{BASE_URL}/model/health-check",
            json=payload,
            headers={"Content-Type": "application/json"}
        )
        response.raise_for_status()
        
        data = response.json()
        print("\nğŸ” í—¬ìŠ¤ì²´í¬ ê²°ê³¼")
        print("=" * 50)
        print(f"ìƒíƒœ: {data['status']}")
        print(f"ì²´í¬ ì‹œê°„: {datetime.fromtimestamp(data['timestamp']).strftime('%Y-%m-%d %H:%M:%S')}")
        
        metrics = data['metrics']
        print("\nğŸ“Š ìƒì„¸ ë©”íŠ¸ë¦­:")
        print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {metrics['response_time_avg']:.2f}ì´ˆ")
        print(f"  95% ì‘ë‹µì‹œê°„: {metrics['response_time_p95']:.2f}ì´ˆ")
        print(f"  ì—ëŸ¬ìœ¨: {metrics['error_rate']:.1%}")
        print(f"  ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {metrics['memory_usage']:.1f}%")
        if metrics.get('gpu_memory_usage'):
            print(f"  GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {metrics['gpu_memory_usage']:.1f}%")
        if metrics.get('gpu_temperature'):
            print(f"  GPU ì˜¨ë„: {metrics['gpu_temperature']:.1f}Â°C")
        print(f"  ì²˜ë¦¬ëŸ‰: {metrics['throughput']:.1f} tokens/sec")
        print(f"  í™œì„± ìš”ì²­: {metrics['active_requests']}")
        
        # ì¶”ë¡  í…ŒìŠ¤íŠ¸ ê²°ê³¼
        if data.get('inference_test'):
            test = data['inference_test']
            print(f"\nğŸ§ª ì¶”ë¡  í…ŒìŠ¤íŠ¸:")
            if test['success']:
                print(f"  âœ… ì„±ê³µ")
                print(f"  ì‘ë‹µì‹œê°„: {test['response_time']:.2f}ì´ˆ")
                print(f"  ìƒì„± í† í° ìˆ˜: {test['tokens_generated']}")
            else:
                print(f"  âŒ ì‹¤íŒ¨: {test['error']}")
        
        return data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return None

def get_system_metrics():
    """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        response = requests.get(f"{BASE_URL}/model/metrics/system")
        response.raise_for_status()
        
        data = response.json()
        print("\nğŸ’» ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­")
        print("=" * 50)
        print(f"CPU ì‚¬ìš©ë¥ : {data['cpu_usage_percent']:.1f}%")
        print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {data['memory_usage_percent']:.1f}%")
        print(f"ë””ìŠ¤í¬ ì‚¬ìš©ë¥ : {data['disk_usage_percent']:.1f}%")
        print(f"ë¡œë“œ í‰ê· : {data['load_average']}")
        
        if data.get('gpu_utilization') is not None:
            print(f"GPU ì‚¬ìš©ë¥ : {data['gpu_utilization']:.1f}%")
        if data.get('gpu_memory_total'):
            gpu_memory_gb = data['gpu_memory_total'] / (1024**3)
            gpu_used_gb = data['gpu_memory_used'] / (1024**3)
            print(f"GPU ë©”ëª¨ë¦¬: {gpu_used_gb:.1f}GB / {gpu_memory_gb:.1f}GB ({data['gpu_memory_percent']:.1f}%)")
        if data.get('gpu_temperature'):
            print(f"GPU ì˜¨ë„: {data['gpu_temperature']:.1f}Â°C")
        
        return data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

def get_model_history(hours=24):
    """ëª¨ë¸ ê³¼ê±° ë°ì´í„° ì¡°íšŒ"""
    try:
        response = requests.get(f"{BASE_URL}/model/history?hours={hours}")
        response.raise_for_status()
        
        data = response.json()
        print(f"\nğŸ“ˆ ëª¨ë¸ íˆìŠ¤í† ë¦¬ ({hours}ì‹œê°„)")
        print("=" * 50)
        print(f"ë°ì´í„° í¬ì¸íŠ¸: {data['data_points']}ê°œ")
        
        summary = data['summary']
        print(f"í‰ê·  ì‘ë‹µì‹œê°„: {summary['avg_response_time']:.2f}ì´ˆ")
        print(f"ìµœëŒ€ ì‘ë‹µì‹œê°„: {summary['max_response_time']:.2f}ì´ˆ")
        print(f"í‰ê·  ì—ëŸ¬ìœ¨: {summary['avg_error_rate']:.1%}")
        print(f"ì—…íƒ€ì„: {summary['uptime_percentage']:.1f}%")
        
        print("\nìƒíƒœ ë¶„í¬:")
        for status, count in summary['status_distribution'].items():
            percentage = (count / data['data_points']) * 100
            print(f"  {status}: {count}íšŒ ({percentage:.1f}%)")
        
        return data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ëª¨ë¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

def get_alerts():
    """í˜„ì¬ ì•Œë¦¼ ì¡°íšŒ"""
    try:
        response = requests.get(f"{BASE_URL}/model/alerts")
        response.raise_for_status()
        
        data = response.json()
        print("\nğŸš¨ ëª¨ë¸ ì•Œë¦¼")
        print("=" * 50)
        print(f"ì´ ì•Œë¦¼ ìˆ˜: {data['total_alerts']}")
        print(f"í¬ë¦¬í‹°ì»¬: {data['critical_count']}")
        print(f"ê²½ê³ : {data['warning_count']}")
        
        if data['critical_alerts']:
            print("\nğŸ”´ í¬ë¦¬í‹°ì»¬ ì•Œë¦¼:")
            for alert in data['critical_alerts']:
                print(f"  - {alert['message']}")
        
        if data['warning_alerts']:
            print("\nğŸŸ¡ ê²½ê³  ì•Œë¦¼:")
            for alert in data['warning_alerts']:
                print(f"  - {alert['message']}")
        
        if not data['alerts']:
            print("âœ… í˜„ì¬ í™œì„± ì•Œë¦¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        return data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ì•Œë¦¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

def start_monitoring(interval=30):
    """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
    try:
        response = requests.post(
            f"{BASE_URL}/model/monitoring/start?interval={interval}",
            headers={"Authorization": "Bearer your-api-key"}  # API í‚¤ê°€ í•„ìš”í•œ ê²½ìš°
        )
        response.raise_for_status()
        
        data = response.json()
        print(f"\nâœ… ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨")
        print(f"ëª¨ë‹ˆí„°ë§ ê°„ê²©: {data['monitoring_interval']}ì´ˆ")
        
        return data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨: {e}")
        return None

def stop_monitoring():
    """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
    try:
        response = requests.post(
            f"{BASE_URL}/model/monitoring/stop",
            headers={"Authorization": "Bearer your-api-key"}  # API í‚¤ê°€ í•„ìš”í•œ ê²½ìš°
        )
        response.raise_for_status()
        
        data = response.json()
        print(f"\nğŸ›‘ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨")
        
        return data
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ì‹¤íŒ¨: {e}")
        return None

def continuous_monitoring(interval=10, duration=300):
    """ì—°ì† ëª¨ë‹ˆí„°ë§ (ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ)"""
    print(f"ğŸ”„ {duration}ì´ˆ ë™ì•ˆ {interval}ì´ˆë§ˆë‹¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
    
    start_time = time.time()
    iteration = 0
    
    while time.time() - start_time < duration:
        iteration += 1
        print(f"\n--- ëª¨ë‹ˆí„°ë§ {iteration}íšŒì°¨ ({datetime.now().strftime('%H:%M:%S')}) ---")
        
        # ëª¨ë¸ ìƒíƒœ í™•ì¸
        status = check_model_status()
        
        if status:
            # ìƒíƒœì— ë”°ë¥¸ ëŒ€ì‘
            if status['status'] == 'unhealthy':
                print("ğŸš¨ ëª¨ë¸ ìƒíƒœê°€ ë¹„ì •ìƒì…ë‹ˆë‹¤!")
                get_alerts()
            elif status['status'] == 'degraded':
                print("âš ï¸ ëª¨ë¸ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì„ê³„ê°’ ì²´í¬
            if status['response_time_p95'] > 5.0:
                print(f"âš ï¸ ì‘ë‹µì‹œê°„ì´ ë†’ìŠµë‹ˆë‹¤: {status['response_time_p95']:.2f}ì´ˆ")
            
            if status['error_rate'] > 0.05:
                print(f"âš ï¸ ì—ëŸ¬ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤: {status['error_rate']:.1%}")
            
            if status.get('gpu_memory_usage', 0) > 90:
                print(f"âš ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤: {status['gpu_memory_usage']:.1f}%")
        
        # ë‹¤ìŒ ì²´í¬ê¹Œì§€ ëŒ€ê¸°
        time.sleep(interval)
    
    print(f"\nâœ… ëª¨ë‹ˆí„°ë§ ì™„ë£Œ ({iteration}íšŒ ì²´í¬)")

def benchmark_model_performance(requests_count=10):
    """ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print(f"\nâš¡ ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ({requests_count}íšŒ ìš”ì²­)")
    print("=" * 50)
    
    test_prompts = [
        "Pythonì´ë€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ë¨¸ì‹ ëŸ¬ë‹ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¢…ë¥˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
        "ì›¹ ê°œë°œì˜ ê¸°ë³¸ ê°œë…ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "í´ë¼ìš°ë“œ ì»´í“¨íŒ…ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    response_times = []
    success_count = 0
    
    for i in range(requests_count):
        prompt = test_prompts[i % len(test_prompts)]
        
        try:
            start_time = time.time()
            
            response = requests.post(
                f"{BASE_URL}/generate",
                json={
                    "prompt": prompt,
                    "max_tokens": 50,
                    "temperature": 0.7
                },
                headers={"Content-Type": "application/json"},
                timeout=30
            )
            
            end_time = time.time()
            response_time = end_time - start_time
            
            if response.status_code == 200:
                success_count += 1
                response_times.append(response_time)
                print(f"  ìš”ì²­ {i+1}: âœ… {response_time:.2f}ì´ˆ")
            else:
                print(f"  ìš”ì²­ {i+1}: âŒ HTTP {response.status_code}")
            
        except requests.exceptions.Timeout:
            print(f"  ìš”ì²­ {i+1}: â° íƒ€ì„ì•„ì›ƒ")
        except requests.exceptions.RequestException as e:
            print(f"  ìš”ì²­ {i+1}: âŒ ì˜¤ë¥˜: {e}")
        
        # ìš”ì²­ ê°„ ê°„ê²©
        time.sleep(0.5)
    
    # ê²°ê³¼ ë¶„ì„
    if response_times:
        avg_time = sum(response_times) / len(response_times)
        min_time = min(response_times)
        max_time = max(response_times)
        success_rate = (success_count / requests_count) * 100
        
        print(f"\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:")
        print(f"  ì„±ê³µë¥ : {success_rate:.1f}% ({success_count}/{requests_count})")
        print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {avg_time:.2f}ì´ˆ")
        print(f"  ìµœì†Œ ì‘ë‹µì‹œê°„: {min_time:.2f}ì´ˆ")
        print(f"  ìµœëŒ€ ì‘ë‹µì‹œê°„: {max_time:.2f}ì´ˆ")
        print(f"  ì´ˆë‹¹ ìš”ì²­ ìˆ˜: {1/avg_time:.1f} RPS")
    else:
        print("âŒ ì„±ê³µí•œ ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¤– vLLM ëª¨ë¸ ìƒíƒœ ì²´í¬ ë„êµ¬")
    print("=" * 60)
    
    while True:
        print("\nì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ëª¨ë¸ ìƒíƒœ í™•ì¸")
        print("2. í—¬ìŠ¤ì²´í¬ ì‹¤í–‰")
        print("3. ì¶”ë¡  í…ŒìŠ¤íŠ¸ í¬í•¨ í—¬ìŠ¤ì²´í¬")
        print("4. ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¡°íšŒ")
        print("5. ëª¨ë¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ")
        print("6. ì•Œë¦¼ ì¡°íšŒ")
        print("7. ëª¨ë‹ˆí„°ë§ ì‹œì‘")
        print("8. ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
        print("9. ì—°ì† ëª¨ë‹ˆí„°ë§ (5ë¶„)")
        print("10. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        print("0. ì¢…ë£Œ")
        
        try:
            choice = input("\nì„ íƒ (0-10): ").strip()
            
            if choice == "0":
                print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            elif choice == "1":
                check_model_status()
            elif choice == "2":
                run_health_check()
            elif choice == "3":
                test_prompt = input("í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ (ì—”í„°: ê¸°ë³¸ê°’): ").strip()
                run_health_check(include_inference=True, test_prompt=test_prompt or None)
            elif choice == "4":
                get_system_metrics()
            elif choice == "5":
                hours = input("ì¡°íšŒí•  ì‹œê°„ (ê¸°ë³¸: 24): ").strip()
                hours = int(hours) if hours.isdigit() else 24
                get_model_history(hours)
            elif choice == "6":
                get_alerts()
            elif choice == "7":
                interval = input("ëª¨ë‹ˆí„°ë§ ê°„ê²© ì´ˆ (ê¸°ë³¸: 30): ").strip()
                interval = int(interval) if interval.isdigit() else 30
                start_monitoring(interval)
            elif choice == "8":
                stop_monitoring()
            elif choice == "9":
                continuous_monitoring(interval=10, duration=300)
            elif choice == "10":
                count = input("ìš”ì²­ ìˆ˜ (ê¸°ë³¸: 10): ").strip()
                count = int(count) if count.isdigit() else 10
                benchmark_model_performance(count)
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            break
        except ValueError:
            print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()